{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JUPYTER 환경에서 진행하였습니다. 코드상의 파일 경로가 수정되어서 진행되었습니다.\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import cv2\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_img_size = (128, 128)\n",
    "arg_dense_sift = True\n",
    "args_local_cluster = 200\n",
    "args_global_cluster = 200\n",
    "num_frame = 5\n",
    "args_aggr = \"bow\"#\"vlad\" \n",
    "pca_vlad = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 비디오의 행동 분류 label read\n",
    "root = \"/kaggle/input/2021-ml-tp4/\"\n",
    "train_csv = pd.read_csv('train_label.csv')\n",
    "train_csv_arr = np.asarray(train_csv)\n",
    "\n",
    "# 데이터 셋에 존재하는 행동 분류 정보 read\n",
    "classinfo = pd.read_csv(\"class_info.csv\")\n",
    "classinfo_arr = np.asarray(classinfo)\n",
    "\n",
    "\n",
    "# train 비디오 경로\n",
    "train_list = os.listdir(\"train\")\n",
    "train_list.sort()\n",
    "train_list = [os.path.join(\"train\", i) for i in train_list]\n",
    "\n",
    "# test 비디오 경로\n",
    "test_list = os.listdir(\"test\")\n",
    "test_list.sort()\n",
    "test_list = [os.path.join(\"test\", i) for i in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frame(video_path, size, num_frame):\n",
    "    \n",
    "    #########################################################\n",
    "    ## 비디오에서 프레임을 추출해주는 함수\n",
    "    ## \n",
    "    ## Input \n",
    "    ##     video_path : 한 비디오의 경로\n",
    "    ##     size : 비디오 내의 프레임을 읽을 때, 원하는 해상도 크기\n",
    "    ##     num_frames : 한 비디오 내에서 읽을 프레임의 수\n",
    "    ##\n",
    "    ## Output\n",
    "    ##     frames : 읽고 저장한 총 프레임\n",
    "    #########################################################\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 한 비디오의 총 프레임 수 반환 및 원하는 프레임 수 많큼 읽기 위해 읽을 프레임의 인덱스 설정\n",
    "    total_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sel_ind = np.linspace(0, total_frame-1, num_frame).astype(\"int\")\n",
    "    \n",
    "    \n",
    "    num=0\n",
    "    frames = []\n",
    "    for i in range(total_frame):\n",
    "        \n",
    "        # 읽을 프레임 인덱스의 경우 프레임 읽어 메모리에 저장, 아닐 경우 지나감\n",
    "        if i in sel_ind:\n",
    "            res, frame = cap.read()\n",
    "            # 원하는 해상도로 조절 및 grayscale로 변환\n",
    "            frame = cv2.resize(frame, size, interpolation = cv2.INTER_CUBIC)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            res = cap.grab()        \n",
    "    cap.release()\n",
    "    frames = np.asarray(frames)\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSIFT(data, dense=False):\n",
    "    \n",
    "    #########################################################\n",
    "    ## 비디오 내의 프레임에서 특징점(visual word)을 SIFT or DenseSIFT로 추출해주는 함수\n",
    "    ## \n",
    "    ## Input \n",
    "    ##     data : 한 비디오에서 읽고 저장한 프레임\n",
    "    ##     dense : SIFT or DenseSIFT 사용 여부\n",
    "    ##\n",
    "    ## Output\n",
    "    ##     x : 프레임에 대해 추출된 특징점(visual word), dict 형태 -> x[0]이면 0번째 인덱스 프레임의 특징점(visual word) [n,128] 확인 가능\n",
    "    #########################################################\n",
    "    \n",
    "    x = {}\n",
    "    for i in range(0, len(data)):\n",
    "        if dense:\n",
    "            img = data[i]\n",
    "            step_size = 8\n",
    "            kp = [cv2.KeyPoint(x, y, step_size) for x in range(0, img.shape[0], step_size) for y in range(0, img.shape[1], step_size)]\n",
    "            \n",
    "            ####### Empty Module 1 : DenseSIFT ########\n",
    "            # 기본 SIFT 와 동일하게 정의 \n",
    "            # 기본 SIFT 에서는 detectAndCompute를 사용했지만 \n",
    "            # Dense SIFT는 위에서 생성한 keypoint를 사용해 compute 만을 진행 \n",
    "            ###########################################\n",
    "            sift = cv2.SIFT_create() #SIFT와 동일하게 정의\n",
    "            _, desc = sift.compute(img, kp) #츨력과정에서 descriptor만 필요하여서 다음과 같이 설정\n",
    "        else:\n",
    "            sift = cv2.SIFT_create()\n",
    "            img = data[i]\n",
    "            kp, desc = sift.detectAndCompute(img, None)\n",
    "        x.update({i : desc})\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract dsift in train data: 100%|█████████████████████████████████████████████████| 2020/2020 [01:14<00:00, 27.02it/s]\n",
      "Extract dsift in test data: 100%|████████████████████████████████████████████████████| 505/505 [00:15<00:00, 32.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# train 비디오에서 프레임 추출 및 특징점(visual word) 추출, dict 형태로 train_local_desc[비디오 경로]이면 해당하는 비디오에서 추출한 모든 특징점(visual word) 확인 가능\n",
    "train_local_desc = {}\n",
    "for vi, vid_path in enumerate(tqdm.tqdm(train_list, desc=\"Extract {} in train data\".format(\"dsift\" if arg_dense_sift else \"sift\"))):\n",
    "    curr_frame = video_to_frame(vid_path, arg_img_size, num_frame)\n",
    "    local_desc = computeSIFT(curr_frame, arg_dense_sift)\n",
    "    train_local_desc.update({vid_path : local_desc})\n",
    "\n",
    "# test 비디오에서 프레임 추출 및 특징점(visual word) 추출, dict 형태로 test_local_desc[비디오 경로]이면 해당하는 비디오에서 추출한 모든 특징점(visual word) 확인 가능\n",
    "test_local_desc = {}\n",
    "for vi, vid_path in enumerate(tqdm.tqdm(test_list, desc=\"Extract {} in test data\".format(\"dsift\" if arg_dense_sift else \"sift\"))):\n",
    "    curr_frame = video_to_frame(vid_path, arg_img_size, num_frame)\n",
    "    local_desc = computeSIFT(curr_frame, arg_dense_sift)\n",
    "    test_local_desc.update({vid_path : local_desc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregate SIFT descriptor\n",
      "\t9.86s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nAggregate SIFT descriptor\")\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# train 비디오 별로 나눠진 특징점(visual word)들을 [n,128]형태로 모음, 모아진 특징점(visual word)들의 정보(비디오 내의 몇번째 프레임에서 나온 특징점인지)는 \n",
    "# 같은 인덱스의 train_frame_total에서 확인 가능 및 비디오 내의 특정 프레임에서 나온 특징점(visual word)의 수는 train_local_info에서 확인 가능\n",
    "train_frame_total = []\n",
    "train_local_desc_total = []\n",
    "train_local_info = {}\n",
    "for k, v in train_local_desc.items():\n",
    "    for kk, vv in v.items():\n",
    "        l_num = 0\n",
    "        if vv is not None:\n",
    "            train_local_desc_total.extend(vv)\n",
    "            train_frame_total.extend([k+\", \"+str(kk)] * len(vv))\n",
    "            l_num = len(vv)\n",
    "        train_local_info.update({k+\", \"+str(kk) : l_num})\n",
    "train_local_desc_total = np.asarray(train_local_desc_total)\n",
    "train_frame_total = np.asarray(train_frame_total)\n",
    "\n",
    "\n",
    "# test 비디오 별로 나눠진 특징점(visual word)들을 [n,128]형태로 모음, 모아진 특징점(visual word)들의 정보(비디오 내의 몇번째 프레임에서 나온 특징점인지)는 \n",
    "# 같은 인덱스의 test_frame_total에서 확인 가능 및 비디오 내의 특정 프레임에서 나온 특징점(visual word)의 수는 test_local_info에서 확인 가능\n",
    "test_frame_total = []\n",
    "test_local_desc_total = []\n",
    "test_local_info = {}\n",
    "for k, v in test_local_desc.items():\n",
    "    for kk, vv in v.items():\n",
    "        l_num = 0\n",
    "        if vv is not None:\n",
    "            test_local_desc_total.extend(vv)\n",
    "            test_frame_total.extend([k+\", \"+str(kk)] * len(vv))\n",
    "            l_num = len(vv)\n",
    "        test_local_info.update({k+\", \"+str(kk) : l_num})\n",
    "test_local_desc_total = np.asarray(test_local_desc_total)\n",
    "test_frame_total = np.asarray(test_frame_total)\n",
    "\n",
    "\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(train_desc, test_desc=None, n_clusters=200):\n",
    "    #########################################################\n",
    "    ## 모든 특징점들 중, 대표 특징점(codebook)을 선정하는 함수\n",
    "    ## \n",
    "    ## Input \n",
    "    ##     train_desc : 모든 train 비디오의 모든 프레임에서 추출한 특징점(visual word)들\n",
    "    ##     test_desc : 모든 test 비디오의 모든 프레임에서 추출한 특징점(visual word)들\n",
    "    ##     n_clusters : 대표 특징점(codebook)의 수\n",
    "    ##\n",
    "    ## Output\n",
    "    ##     train_pred : 대표 특징점(codebook)에 대해 train_desc가 할당된 위치\n",
    "    ##     test_pred : 대표 특징점(codebook)에 대해 train_desc가 할당된 위치\n",
    "    ##     clusters : 대표 특징점(codebook)\n",
    "    ##     kmeans : kmeans 인스턴스\n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Empty Module 2 : 대표 특징점(codebook) 선정 ######\n",
    "    # 제약 조건 : MiniBatchKMeans 사용, random_state=0 고정\n",
    "    # sklearn의 MiniBatchKMeans를 활용하여 n_clusters 크기 만큼의 대표 특징점(codebook)을 선정\n",
    "    ###########################################\n",
    "    kmeans = MiniBatchKMeans(n_clusters = n_clusters, random_state = 0) #MininBatchKMeans 선언\n",
    "    kmeans.fit(train_desc) #학습\n",
    "    clusters = kmeans.cluster_centers_ #학습 결과 획득한 클러스터링한 중심을 가져옴\n",
    "    train_pred = kmeans.predict(train_desc) #예측\n",
    "    if test_desc is not None:\n",
    "        test_pred = kmeans.predict(test_desc)\n",
    "    else:\n",
    "        test_pred = None\n",
    "    return train_pred, test_pred, clusters, kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoons\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 2048 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모든 train 비디오의 모든 프레임에서 추출한 특징점(visual word)들로 대표 특징점(codebook)을 만들고,\n",
    "# train 비디오의 모든 프레임에서 추출된 특징점(visual word)과 test 비디오의 모든 프레임에서 추출된 특징점(visual word)을 대표 특징점(codebook)에 할당\n",
    "train_local_alloc, test_local_alloc, local_codebook, local_kmeans = clustering(train_local_desc_total, test_local_desc_total, args_local_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2585600, 128)\n",
      "(2585600,)\n",
      "(200, 128)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_local_desc_total)) #데이터 구조 확인 과정\n",
    "print(np.shape(train_local_alloc))\n",
    "print(np.shape(local_codebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3010\n",
      "(array([  3894,   3910,   3926, ..., 645211, 645227, 645451], dtype=int64),)\n",
      "3894\n"
     ]
    }
   ],
   "source": [
    "index = np.where(test_local_alloc == 1) #where() 작동 방식 체크 과정\n",
    "list(index) #반환 값이 array 구조\n",
    "print(len(index[0]))\n",
    "print(index)\n",
    "print(index[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VLAD(X, alloc, centers):\n",
    "    #########################################################\n",
    "    ## 이미지 feature인 VLAD feature를 기술하기 위한 함수\n",
    "    ## \n",
    "    ## Input \n",
    "    ##     X : 한 프레임의 특징점(visual word)들\n",
    "    ##     alloc : 한 프레임의 특징점(visual word)들이 대표 특징점(codebook)에 할당된 위치\n",
    "    ##     centers : 대표 특징점(codebook)\n",
    "    ##\n",
    "    ## Output\n",
    "    ##     V : VLAD feature\n",
    "    #########################################################\n",
    "    \n",
    "    m,d = X.shape\n",
    "    k = centers.shape[0]\n",
    "    \n",
    "    # VLAD feature를 담기 위한 변수\n",
    "    V=np.zeros([k,d])\n",
    "\n",
    "    for i in range(k):\n",
    "        if np.sum(alloc==i)>0:\n",
    "            index = np.where(alloc == i) #where()로 조건에 맞는 값 확인\n",
    "            for j in range(len(index[0])): #VLAD feature 계산을 위한 반복문\n",
    "                V[i]= V[i] + X[index[0][j]] -centers[i] #계산식\n",
    "            ####################### Empty Module 3 : VLAD ########################\n",
    "            # 이미지에서 추출된 특징점(visual word) X와 이들이 대표 특징점(codebook)으로 할당된 정보 alloc을 이용해,\n",
    "            # 동일한 대표 특징점(codebook)으로 할당된 특징점(visual word)들의 벡터 합 계산해 V[i]에 저장\n",
    "            # hint : 바로 위 조건문의 조건 \"alloc==i\"의 의미를 파악하고 인덱싱에 활용\n",
    "            ######################################################################\n",
    "    \n",
    "    # 후처리 과정\n",
    "    V = V.flatten()\n",
    "    V = np.sign(V)*np.sqrt(np.abs(V))\n",
    "    if np.sqrt(np.dot(V,V))!=0:\n",
    "        V = V/np.sqrt(np.dot(V,V))\n",
    "    return V\n",
    "\n",
    "\n",
    "def BoW(alloc, n_cluster):\n",
    "    #########################################################\n",
    "    ## 이미지 feature인 BoW feature를 기술하기 위한 함수\n",
    "    ## \n",
    "    ## Input \n",
    "    ##     alloc : 한 프레임의 특징점(visual word)들이 대표 특징점(codebook)에 할당된 위치\n",
    "    ##     n_cluster : 대표 특징점(codebook)의 수\n",
    "    ##\n",
    "    ## Output\n",
    "    ##     V : BoW feature\n",
    "    #########################################################\n",
    "    V, bins = np.histogram(alloc,bins=range(n_cluster)) #Bow feature 사용 과정\n",
    "    ######################### Empty Module 4 : BoW ##########################\n",
    "    # 이미지에서 추출된 특징점(visual word)이 대표 특징점(codebook)으로 할당된 정보 alloc의 histogram을 계산\n",
    "    # np.histogram 함수 참고\n",
    "    #########################################################################\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Allocate center & Descript local histogram\n",
      "\t1.59s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nAllocate center & Descript local histogram\")\n",
    "start = time.time()\n",
    "\n",
    "# Train 비디오 내의 프레임 별로 이미지 feature 기술 -> train_global_desc\n",
    "# 각 이미지 feature의 정보(속한 비디오 이름, 비디오 내의 인덱스) -> train_global_desc_key\n",
    "train_global_desc = []\n",
    "train_global_desc_key = []\n",
    "vi=0\n",
    "for k, v in train_local_info.items():\n",
    "    if v!=0:\n",
    "        if args_aggr==\"bow\":            \n",
    "            hist_desc = BoW(train_local_alloc[vi:vi+v], args_local_cluster)\n",
    "        elif args_aggr==\"vlad\":\n",
    "            hist_desc = VLAD(train_local_desc_total[vi:vi+v], train_local_alloc[vi:vi+v], local_codebook)\n",
    "        else:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        vi+=v\n",
    "        train_global_desc.append(hist_desc)\n",
    "        train_global_desc_key.append(k)\n",
    "train_global_desc = np.asarray(train_global_desc)\n",
    "train_global_desc_key = np.asarray(train_global_desc_key)\n",
    "\n",
    "\n",
    "# Test 비디오 내의 프레임 별로 이미지 feature 기술 -> test_global_desc\n",
    "# 각 이미지 feature의 정보(속한 비디오 이름, 비디오 내의 인덱스) -> test_global_desc_key\n",
    "test_global_desc = []\n",
    "test_global_desc_key = []\n",
    "vi=0\n",
    "for k, v in test_local_info.items():\n",
    "    if v!=0:\n",
    "        if args_aggr==\"bow\":\n",
    "            hist_desc = BoW(test_local_alloc[vi:vi+v], args_local_cluster)\n",
    "        elif args_aggr==\"vlad\":\n",
    "            hist_desc = VLAD(test_local_desc_total[vi:vi+v], test_local_alloc[vi:vi+v], local_codebook)\n",
    "        else:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        vi+=v\n",
    "        test_global_desc.append(hist_desc)\n",
    "        test_global_desc_key.append(k)\n",
    "test_global_desc = np.asarray(test_global_desc)\n",
    "test_global_desc_key = np.asarray(test_global_desc_key)\n",
    "\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 199)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_global_desc) #데이터 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_global_desc_key) #데이터 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLAD feature의 경우 큰 차원으로 인해 메모리 부족 현상이 발생하므로 PCA를 이용한 차원 축소\n",
    "if args_aggr==\"vlad\":\n",
    "    print(\"\\n\\nReduce dim of descriptor of the frames with PCA\")\n",
    "    start = time.time()\n",
    "    pca = PCA(n_components=pca_vlad, random_state=0)\n",
    "    pca.fit(train_global_desc)\n",
    "    train_global_desc = pca.transform(train_global_desc)\n",
    "    test_global_desc = pca.transform(test_global_desc)\n",
    "    print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing label\n",
      "\t0.49s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nProcessing label\")\n",
    "start = time.time()\n",
    "\n",
    "# 분류를 위해, 행동 분류에 대한 train 비디오의 각 프레임 별 label 가공\n",
    "train_global_id = np.array([int(i.split(\"\\\\\")[-1].split(\".\")[0]) for i in train_global_desc_key])\n",
    "train_global_label = []\n",
    "for fid in train_global_id:\n",
    "    cind = np.where(train_csv_arr[:, 0]==fid)[0]\n",
    "    clsname = train_csv_arr[cind, 1]\n",
    "    cinfo_ind = np.where(classinfo_arr[:, 1] == clsname)[0]\n",
    "    train_global_label.append(classinfo_arr[cinfo_ind, 0].astype(\"int\"))\n",
    "train_global_label = np.asarray(train_global_label).ravel()\n",
    "\n",
    "# 분류를 위해, 행동 분류에 대한 test 비디오의 각 프레임 별 id 가공 \n",
    "test_global_id = np.array([int(i.split(\"\\\\\")[-1].split(\".\")[0]) for i in test_global_desc_key])\n",
    "\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFile(predict, predict_id, name, best_params=None):\n",
    "    #########################################################\n",
    "    ## 결과를 저장하기 위한 함수\n",
    "    ## \n",
    "    ## Input \n",
    "    ##     predict : 모든 test 비디오의 행동 예측 값\n",
    "    ##     predict_id : 모든 test 비디오의 id\n",
    "    ##     name : 원하는 저장 파일 이름\n",
    "    ##     best_params : 원하는 instance 저장 시 사용\n",
    "    ##\n",
    "    #########################################################\n",
    "    \n",
    "    data = np.concatenate((np.expand_dims(predict_id.astype(\"str\"), axis=1), np.expand_dims(predict.astype(\"str\"), axis=1)), axis=1)\n",
    "    csv = pd.DataFrame(data, columns=['Id', 'Category'])\n",
    "    csv.to_csv(name + \".csv\", index=False)\n",
    "    \n",
    "    if best_params:\n",
    "        f = open(name + \".pickle\", \"wb\")\n",
    "        pickle.dump(best_params, f, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 504, 504, 504])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_global_id #데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 199)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_global_desc) #데이터 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2017, 2018, 2019])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_global_id) #데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SVM global averaging in frame\n",
      "\t66.99s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nSVM global averaging in frame\")\n",
    "start = time.time()\n",
    "#################### Empty Module 6 : SVM (averaging) ######################\n",
    "# 제약조건 : sklearn의 SVC 사용 및 random_state=0으로 고정\n",
    "# 각 프레임을 나타내는 이미지 feature를 비디오 별로 평균 내어 비디오 feature로 사용\n",
    "# 비디오 feature로 학습 후, 행동 예측\n",
    "# hint : 위 셀에서 선언한 train_global_id, train_global_label, test_global_id 활용\n",
    "###########################################################################\n",
    "parameters = {'kernel':['rbf', 'poly', 'sigmoid'], 'C':[0.01, 0.1 ,1, 10, 100, 1000]} #파라미터 설정\n",
    "model=GridSearchCV(SVC(kernel = 'linear'),parameters,cv=5) #GridSearchCV 사용\n",
    "train_global_desc_average = [] #리스트 선언\n",
    "train_global_label_average = []\n",
    "test_global_desc_average = []\n",
    "np.array(train_global_desc_average)#구조 선언\n",
    "np.array(train_global_label_average)\n",
    "np.array(test_global_desc_average)\n",
    "\n",
    "for i in range(2019):\n",
    "    train_global_desc_average.append(np.mean(train_global_desc[5*i : 5*i+5], axis = 0)) #average feature 사용을 위한 계산식\n",
    "    train_global_label_average.append(np.mean(train_global_label[5*i : 5*i+5], axis = 0).astype(int)) #average 후 데이터 타입 선언\n",
    "for i in range(505):\n",
    "    test_global_desc_average.append(np.mean(test_global_desc[5*i : 5*i+5], axis = 0)) #average feature 사용을 위한 계산식\n",
    "#print(np.shape(train_global_desc_average))\n",
    "#print(np.shape(train_global_label_average))\n",
    "#print(np.shape(test_global_desc_average))\n",
    "model.fit(train_global_desc_average, train_global_label_average) #학습\n",
    "svm_predict = model.predict(test_global_desc_average) #예측\n",
    "#print(np.shape(svm_predict))\n",
    "saveFile(classinfo_arr[svm_predict][:,1], np.arange(len(test_list)), \"svm_global_averaging\")\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SVM global voting in frame\n",
      "\t1164.26s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nSVM global voting in frame\")\n",
    "start = time.time()\n",
    "############################### Empty Module 5 : SVM (voting) ##################################\n",
    "# 제약조건 : sklearn의 SVC 사용 및 random_state=0으로 고정\n",
    "# 각 프레임을 나타내는 이미지 feature를 모두 사용해 SVM 학습\n",
    "# 학습 시, 각 이미지 feature의 label은 해당되는 비디오의 label(행동)로 사용\n",
    "# 프레임 별로 행동 예측 후, 같은 비디오 내 프레임의 행동 예측 값의 최빈값을 해당 비디오의 행동 예측 값으로 선정\n",
    "# hint : 위 셀에서 선언한 train_global_label, test_global_id 및 mode 활용\n",
    "################################################################################################\n",
    "model.fit(train_global_desc, train_global_label)\n",
    "svm_predict = []\n",
    "test_predict = model.predict(test_global_desc)\n",
    "#print(np.shape(test_predict))\n",
    "for i in range(505):\n",
    "    #print((mode(test_predict[5*i : 5*i+5])[0])[0])\n",
    "    svm_predict.append((mode(test_predict[5*i : 5*i+5])[0])[0]) #mode를 활용하여 voting 결과 추출\n",
    "\n",
    "#print(np.shape(svm_predict))\n",
    "saveFile(classinfo_arr[svm_predict][:,1], np.arange(len(test_list)), \"svm_global_voting\")\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoons\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 2048 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_global_alloc, test_global_alloc, global_codebook, global_kmeans = clustering(train_global_desc, test_global_desc, args_global_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Allocate center & Descript global histogram\n",
      "\t0.51s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nAllocate center & Descript global histogram\")\n",
    "start = time.time()\n",
    "train_vid_names = np.asarray([i.split(\", \")[0] for i in train_global_desc_key])\n",
    "train_vid_names_u = np.unique(train_vid_names)\n",
    "\n",
    "# Train 비디오 내 프레임 별로 기술된 이미지 feature를 기반으로 한번 더 기술하여(한번 더 BoW 혹은 VLAD)\n",
    "# 각 비디오에 대한 비디오 feature 기술\n",
    "# Empty Module 7과 관련있으며, 5,6과는 무관\n",
    "train_video_desc = []\n",
    "train_video_desc_key = []\n",
    "for vid_name in train_vid_names_u:\n",
    "    cind = np.where(vid_name==train_vid_names)[0]\n",
    "    if args_aggr==\"bow\":\n",
    "        hist_desc = BoW(train_global_alloc[cind], args_global_cluster)\n",
    "    elif args_aggr==\"vlad\":\n",
    "        hist_desc = VLAD(train_global_desc[cind], train_global_alloc[cind], global_codebook)\n",
    "    else:\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "    train_video_desc.append(hist_desc)\n",
    "    train_video_desc_key.append(vid_name)\n",
    "train_video_desc = np.asarray(train_video_desc)\n",
    "train_video_desc_key = np.asarray(train_video_desc_key)\n",
    "\n",
    "# Test 비디오 내 프레임 별로 기술된 이미지 feature를 기반으로 한번 더 기술하여(한번 더 BoW 혹은 VLAD)\n",
    "# 각 비디오에 대한 비디오 feature 기술\n",
    "# Empty Module 7과 관련있으며, 5,6과는 무관\n",
    "test_vid_names = np.asarray([i.split(\", \")[0] for i in test_global_desc_key])\n",
    "test_vid_names_u = np.unique(test_vid_names)\n",
    "\n",
    "test_video_desc = []\n",
    "test_video_desc_key = []\n",
    "for vid_name in test_vid_names_u:\n",
    "    cind = np.where(vid_name==test_vid_names)[0]\n",
    "    if args_aggr==\"bow\":\n",
    "        hist_desc = BoW(test_global_alloc[cind], args_global_cluster)\n",
    "    elif args_aggr==\"vlad\":\n",
    "        hist_desc = VLAD(test_global_desc[cind], test_global_alloc[cind], global_codebook)\n",
    "    else:\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "    test_video_desc.append(hist_desc)\n",
    "    test_video_desc_key.append(vid_name)\n",
    "test_video_desc = np.asarray(test_video_desc)\n",
    "test_video_desc_key = np.asarray(test_video_desc_key)\n",
    "\n",
    "\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing label\n",
      "\t0.09s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nProcessing label\")\n",
    "start = time.time()\n",
    "\n",
    "# 분류를 위해, 행동 분류에 대한 각 train 비디오 별 label 가공\n",
    "train_video_id = np.array([int(i.split(\"\\\\\")[-1].split(\".\")[0]) for i in train_video_desc_key])\n",
    "train_video_label = []\n",
    "for fid in train_video_id:\n",
    "    cind = np.where(train_csv_arr[:, 0]==fid)[0]\n",
    "    clsname = train_csv_arr[cind, 1]\n",
    "    cinfo_ind = np.where(classinfo_arr[:, 1] == clsname)[0]\n",
    "    train_video_label.append(classinfo_arr[cinfo_ind, 0].astype(\"int\"))\n",
    "train_video_label = np.asarray(train_video_label).ravel()\n",
    "\n",
    "# 분류를 위해, 행동 분류에 대한 각 test 비디오 별 id 가공\n",
    "test_video_id = np.array([int(i.split(\"\\\\\")[-1].split(\".\")[0]) for i in test_video_desc_key])\n",
    "\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 feature에 대해 다시 한번 VLAD feature 기술 방식을 사용하여 video feature를 기술한 경우 큰 차원으로 인해 메모리 부족 현상이 발생하므로 PCA를 이용한 차원 축소\n",
    "if args_aggr==\"vlad\":\n",
    "    print(\"\\n\\nReduce dim of descriptor of the frames with PCA\")\n",
    "    start = time.time()\n",
    "    pca = PCA(n_components=pca_vlad, random_state=0)\n",
    "    pca.fit(train_video_desc)\n",
    "    train_video_desc = pca.transform(train_video_desc)\n",
    "    test_video_desc = pca.transform(test_video_desc)\n",
    "    print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2020, 199)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_video_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2020,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_video_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SVM video descriptor\n",
      "\t53.19s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nSVM video descriptor\")\n",
    "start = time.time()\n",
    "######################## Empty Module 7 : SVM (video feature) ##########################\n",
    "# 제약조건 : sklearn의 SVC 사용 및 random_state=0으로 고정\n",
    "# 이전 이미지 feature를 기반으로 각 기술방식(BoW, VLAD)을 한번 더 적용해 만든 비디오 feature 사용\n",
    "# 비디오 feature로 학습 후, 행동 예측\n",
    "#######################################################################################\n",
    "model.fit(train_video_desc, train_video_label) #기존에 선언했던 모델 사용\n",
    "svm_predict = model.predict(test_video_desc) #예측\n",
    "saveFile(classinfo_arr[svm_predict][:,1], test_video_id, \"svm_video\")\n",
    "print(\"\\t{:3.2f}s\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
